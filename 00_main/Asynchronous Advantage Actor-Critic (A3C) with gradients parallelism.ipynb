{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Advantage Actor-Critic (A3C) with gradients parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Chapter13/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import ptan\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils as nn_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from lib import common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we define the hyperparameters, which are mostly the same as in the\n",
    "previous example, except BATCH_SIZE is replaced by two parameters: \n",
    "- GRAD_BATCH\n",
    "- TRAIN_BATCH. \n",
    "\n",
    "The value of GRAD_BATCH defines the size of the batch used by\n",
    "every child process to compute the loss and get the value of the gradients. The\n",
    "second parameter, TRAIN_BATCH, specifies how many gradient batches from the child\n",
    "processes will be combined on every SGD iteration. Every entry produced by the\n",
    "child process has the same shape as our network parameters, and we sum up TRAIN_\n",
    "BATCH values of them together. So, for every optimization step, we use the TRAIN_\n",
    "BATCH * GRAD_BATCH training samples. As the loss calculation and backpropagation\n",
    "are quite heavy operations, we use large GRAD_BATCH to make them more efficient.\n",
    "\n",
    "Due to this large batch, we should keep TRAIN_BATCH relatively low to keep our\n",
    "network update on-policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.001\n",
    "ENTROPY_BETA = 0.01\n",
    "\n",
    "REWARD_STEPS = 4\n",
    "CLIP_GRAD = 0.1\n",
    "\n",
    "PROCESSES_COUNT = 4\n",
    "NUM_ENVS = 8\n",
    "\n",
    "GRAD_BATCH = 64\n",
    "TRAIN_BATCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "    NAME = 'pong'\n",
    "    REWARD_BOUND = 18\n",
    "else:\n",
    "    ENV_NAME = \"BreakoutNoFrameskip-v4\"\n",
    "    NAME = \"breakout\"\n",
    "    REWARD_BOUND = 400\n",
    "    TRAIN_BATCH = 4\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    return ptan.common.wrappers.wrap_dqn(gym.make(ENV_NAME))\n",
    "\n",
    "\n",
    "def grads_func(proc_name, net, device, train_queue):\n",
    "    envs = [make_env() for _ in range(NUM_ENVS)]\n",
    "\n",
    "    agent = ptan.agent.PolicyAgent(\n",
    "        lambda x: net(x)[0], device=device, apply_softmax=True)\n",
    "    exp_source = ptan.experience.ExperienceSourceFirstLast(\n",
    "        envs, agent, gamma=GAMMA, steps_count=REWARD_STEPS)\n",
    "\n",
    "    batch = []\n",
    "    frame_idx = 0\n",
    "    writer = SummaryWriter(comment=proc_name)\n",
    "\n",
    "    with common.RewardTracker(writer, REWARD_BOUND) as tracker:\n",
    "        with ptan.common.utils.TBMeanTracker(\n",
    "                writer, 100) as tb_tracker:\n",
    "            for exp in exp_source:\n",
    "                frame_idx += 1\n",
    "                new_rewards = exp_source.pop_total_rewards()\n",
    "                if new_rewards and tracker.reward(\n",
    "                        new_rewards[0], frame_idx):\n",
    "                    break\n",
    "\n",
    "                batch.append(exp)\n",
    "                if len(batch) < GRAD_BATCH:\n",
    "                    continue\n",
    "\n",
    "                data = common.unpack_batch(\n",
    "                    batch, net, device=device,\n",
    "                    last_val_gamma=GAMMA**REWARD_STEPS)\n",
    "                states_v, actions_t, vals_ref_v = data\n",
    "\n",
    "                batch.clear()\n",
    "\n",
    "                net.zero_grad()\n",
    "                logits_v, value_v = net(states_v)\n",
    "                loss_value_v = F.mse_loss(\n",
    "                    value_v.squeeze(-1), vals_ref_v)\n",
    "\n",
    "                log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "                adv_v = vals_ref_v - value_v.detach()\n",
    "                log_p_a = log_prob_v[range(GRAD_BATCH), actions_t]\n",
    "                log_prob_actions_v = adv_v * log_p_a\n",
    "                loss_policy_v = -log_prob_actions_v.mean()\n",
    "\n",
    "                prob_v = F.softmax(logits_v, dim=1)\n",
    "                ent = (prob_v * log_prob_v).sum(dim=1).mean()\n",
    "                entropy_loss_v = ENTROPY_BETA * ent\n",
    "\n",
    "                loss_v = entropy_loss_v + loss_value_v + \\\n",
    "                         loss_policy_v\n",
    "                loss_v.backward()\n",
    "\n",
    "                tb_tracker.track(\"advantage\", adv_v, frame_idx)\n",
    "                tb_tracker.track(\"values\", value_v, frame_idx)\n",
    "                tb_tracker.track(\"batch_rewards\", vals_ref_v,\n",
    "                                 frame_idx)\n",
    "                tb_tracker.track(\"loss_entropy\", entropy_loss_v,\n",
    "                                 frame_idx)\n",
    "                tb_tracker.track(\"loss_policy\", loss_policy_v,\n",
    "                                 frame_idx)\n",
    "                tb_tracker.track(\"loss_value\", loss_value_v,\n",
    "                                 frame_idx)\n",
    "                tb_tracker.track(\"loss_total\", loss_v, frame_idx)\n",
    "\n",
    "                # gather gradients\n",
    "                nn_utils.clip_grad_norm_(\n",
    "                    net.parameters(), CLIP_GRAD)\n",
    "                grads = [\n",
    "                    param.grad.data.cpu().numpy()\n",
    "                    if param.grad is not None else None\n",
    "                    for param in net.parameters()\n",
    "                ]\n",
    "                train_queue.put(grads)\n",
    "\n",
    "    train_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-10ad2122da0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_entry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mp.set_start_method('spawn')\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "env = make_env()\n",
    "net = common.AtariA2C(env.observation_space.shape,\n",
    "                      env.action_space.n).to(device)\n",
    "net.share_memory()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                       lr=LEARNING_RATE, eps=1e-3)\n",
    "\n",
    "train_queue = mp.Queue(maxsize=PROCESSES_COUNT)\n",
    "data_proc_list = []\n",
    "for proc_idx in range(PROCESSES_COUNT):\n",
    "    proc_name = f\"-a3c-grad_pong_test_ac3_grad\"\n",
    "    p_args = (proc_name, net, device, train_queue)\n",
    "    data_proc = mp.Process(target=grads_func, args=p_args)\n",
    "    data_proc.start()\n",
    "    data_proc_list.append(data_proc)\n",
    "\n",
    "batch = []\n",
    "step_idx = 0\n",
    "grad_buffer = None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        train_entry = train_queue.get()\n",
    "        if train_entry is None:\n",
    "            break\n",
    "\n",
    "        step_idx += 1\n",
    "\n",
    "        if grad_buffer is None:\n",
    "            grad_buffer = train_entry\n",
    "        else:\n",
    "            for tgt_grad, grad in zip(grad_buffer,\n",
    "                                      train_entry):\n",
    "                tgt_grad += grad\n",
    "\n",
    "        if step_idx % TRAIN_BATCH == 0:\n",
    "            for param, grad in zip(net.parameters(),\n",
    "                                   grad_buffer):\n",
    "                param.grad = torch.FloatTensor(grad).to(device)\n",
    "\n",
    "            nn_utils.clip_grad_norm_(\n",
    "                net.parameters(), CLIP_GRAD)\n",
    "            optimizer.step()\n",
    "            grad_buffer = None\n",
    "finally:\n",
    "    for p in data_proc_list:\n",
    "        p.terminate()\n",
    "        p.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
